\section{Detectors}

In the context of image and video analysis, it is often necessary
to detect interest points, for example edges, corners, etc.
This is important for matching tasks:
comparing descriptors from two images and obtaining correspondences,
estimating image transformations (alignment),
performing tracking in videos from these interest points,
and visual odometry to estimate camera motion.

\subsection{Harris Interest Function}

This is where the Harris function (or detector) comes in,
which is ideal when speed and stability are required.
However, with strong scale changes, for example when
an object appears much larger or much smaller
between different \emph{frames}, the Harris detector is less effective.

The Harris interest function is based on assigning a value to each pixel. This value measures
how much this pixel is an \emph{intersection}, that is, a \emph{corner}.

Saying that a pixel is a corner means we look at how much it resembles the intersection of two edges.
In other words, how much this pixel corresponds to a place where the image changes strongly in two
perpendicular directions. This is useful, because with a small pixel window (the window $W$), we can estimate
how much what we observe changes at the structure level.

Intuitively, if we move the window $W$ slightly around a pixel, we observe:
\begin{itemize}
    \item \textbf{Flat region (no texture)} : the window changes very little $\rightarrow$ this is not a corner.
    \item \textbf{Edge} : the window changes little when moving \emph{along} the edge, but changes a lot
    when \emph{crossing} it.
    \item \textbf{Corner} : the window changes a lot in almost any direction.
\end{itemize}

What Harris does is use the gradients $I_x$ and $I_y$ to know how much intensity changes
 along $x$ and along $y$.
If around the pixel there is a strong change in only one direction, we are mostly on an edge; but if
the strong changes are in two
directions, we call it a corner. Thus, $\Theta$, the Harris response, is defined pixel by pixel: the larger
$\Theta$ is, the more the pixel is a \emph{corner}.

In the Harris detector, the interest function is defined as:
$$
\Theta = R = \det(M) - k\,(\operatorname{trace}(M))^2
$$

Where $k$ is an empirical penalization value: the larger it is, the stricter the criterion,
so fewer corners are detected. $M$ is the structure matrix obtained from the gradients
$I_{x}$ and $I_{y}$, computed after Gaussian smoothing of the image, with parameter $\sigma$ that controls
the smoothing level (noise reduction and fine-detail attenuation). The matrix $M$ is defined as:

$$
M(x,y)=
$$

$$
=\sum_{(u,v)\in W} w(u,v)
\begin{pmatrix}
I_x(u,v)^2 & I_x(u,v)I_y(u,v)\\
I_x(u,v)I_y(u,v) & I_y(u,v)^2
\end{pmatrix}
$$

Where $w(u,v)$ is a weighting function that gives more importance to pixels close to the center
of window $W$. Thus, the sum is computed over a window around the analyzed pixel.

\begin{itemize}
  \item $I_x^2$ measures how much the image changes in the horizontal direction.
  \item $I_y^2$ measures how much the image changes in the vertical direction.
  \item $I_x I_y$ measures the correlation between these two variations.
\end{itemize}

And regarding the eigenvalues of $M$: if both are large, then $R$ is large and the pixel is a
\emph{corner}. If one is large and the other small, then $R$ becomes negative and the pixel corresponds to an
\emph{edge}. If both are small, then $R$ is small and the pixel is a flat region.

Finally, the determinant of $M$ corresponds to the product of the eigenvalues, while the trace corresponds to their
sum. But the trace does not distinguish edges from corners very well, which is why it is penalized (with the
term in $k$). The trace mostly measures global change, while the determinant highlights
a true corner better.

Moreover, this interest function is computed at a single scale: we use one smoothing level
and one window size to compute $M$.

\subsection{Morphological Dilation}

In image processing, we often seek to obtain a
representative value of a neighborhood.
In the case of morphological dilation, this value corresponds,
for each pixel, to the maximum in that neighborhood.
This neighborhood is defined by a structuring element,
for example a $3 \times 3$ window.

In the Harris case, this morphological dilation is used to
detect local maxima and then perform non-maximum suppression.
In other words, the goal is to keep the strongest peaks (the corners).

In the code of \texttt{Harris.py},
the variable \texttt{se} defines the window/neighborhood as a matrix
of ones of size \texttt{d\_maxloc}, with \texttt{d\_maxloc = 3}:

\begin{verbatim}
d_maxloc = 3
se = np.ones(
    (d_maxloc, d_maxloc), np.uint8
)
\end{verbatim}

Then, the following instruction makes each pixel take the value
of the largest value in its window:

\begin{verbatim}
Theta_dil = cv2.dilate(Theta, se)
\end{verbatim}

After that, with the following instruction, we perform a pixel-by-pixel
comparison:

\begin{verbatim}
Theta_maxloc[Theta < Theta_dil] = 0.0
\end{verbatim}

If the original value is different from the dilated value, then this pixel
was not a local maximum, so its value is removed (set to zero).
Otherwise, the value is kept because it is indeed a local maximum.

Finally, we apply a relative threshold to remove maxima that are too weak:

\begin{verbatim}
Theta_maxloc[
    Theta < seuil_relatif * Theta.max()
] = 0.0
\end{verbatim}

\subsection{Results}

The script \texttt{Harris.py} was run 50 times with \texttt{-stats}
on image \texttt{Graffiti0.png}. The following measurements were obtained.
The results below were measured with the following parameters:

\begin{verbatim}
SUM_WINDOW_SIZE = 5
HARRIS_K = 0.04
MAXLOC_NEIGHBORHOOD_SIZE = 3
RELATIVE_THRESHOLD = 0.01
\end{verbatim}

\begin{itemize}
    \item Image size (grayscale) : $320 \times 400$.
    \item Image type (grayscale) : \texttt{float64}.
    \item Image size (color) : $320 \times 400 \times 3$.
    \item Image type (color) : \texttt{uint8}.
\end{itemize}

\begin{table}[H]
    \centering
    \caption{Statistics over 50 runs of the Harris detector}
    \label{tab:harris_stats}
    \begin{tabular}{lc}
        \hline
        Metric & Value \\
        \hline
        Mean time [s] & 0.003224673 \\
        Time variance [s$^2$] & 0.000002632168 \\
        Time standard deviation [s] & 0.001622396 \\
        Mean cycles/pixel [cpp] & 25.192756 \\
        Cycles/pixel variance [cpp$^2$] & 160.654768461 \\
        Cycles/pixel standard deviation [cpp] & 12.674966 \\
        \hline
    \end{tabular}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{../../results/harris_points.png}
    \caption{Visualization of interest points detected by Harris on \texttt{Graffiti0.png}.}
    \label{fig:harris_points}
\end{figure}

\subsection{Parametric Analysis of the Harris Detector}

This parametric study was conducted with command
\texttt{python Harris.py -stats 50 -plots}. The sample corresponds to
50 runs of Harris computation for each tested value.
During each sweep, the other parameters remain fixed to:
\texttt{SUM\_WINDOW\_SIZE = 5}, \texttt{HARRIS\_K = 0.04},
\texttt{MAXLOC\_NEIGHBORHOOD\_SIZE = 3},
\texttt{RELATIVE\_THRESHOLD = 0.01}.

\begin{figure}[H]
    \centering
    \begin{minipage}[t]{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{../../results/plots/harris/cpp_vs_sum_window_size.png}
        \vspace{2mm}
        \textbf{(a)} Cycles/pixel vs \texttt{SUM\_WINDOW\_SIZE}
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{../../results/plots/harris/time_vs_sum_window_size.png}
        \vspace{2mm}
        \textbf{(b)} Mean time vs \texttt{SUM\_WINDOW\_SIZE}
    \end{minipage}
    \caption{Impact of \texttt{SUM\_WINDOW\_SIZE} on computational cost.}
    \label{fig:harris_sum_window_analysis}
\end{figure}

When \texttt{SUM\_WINDOW\_SIZE} increases, mean time and cycles/pixel
increase clearly, because local convolution is more expensive.
From a detection point of view, a large window stabilizes the structure measure
(less sensitive to noise), but tends to smooth fine details and reduce
the number of weak detected corners. Conversely, a small window captures more
micro-variations (more potential corners), at the cost of stronger sensitivity
to noise and therefore a higher risk of false positives.

\begin{figure}[H]
    \centering
    \begin{minipage}[t]{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{../../results/plots/harris/cpp_vs_harris_k.png}
        \vspace{2mm}
        \textbf{(a)} Cycles/pixel vs \texttt{HARRIS\_K}
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{../../results/plots/harris/time_vs_harris_k.png}
        \vspace{2mm}
        \textbf{(b)} Mean time vs \texttt{HARRIS\_K}
    \end{minipage}
    \caption{Impact of \texttt{HARRIS\_K} on computational cost.}
    \label{fig:harris_k_analysis}
\end{figure}

The variation of \texttt{HARRIS\_K} changes the cost only slightly (same computation pipeline,
same main operators), which is consistent with the time/CPP curves.
However, the effect on corner selection is important:
a low \texttt{HARRIS\_K} is more permissive (more points kept, including
ambiguous points near edges), while a high \texttt{HARRIS\_K}
reinforces trace penalization, so selection becomes stricter
and the number of corners tends to decrease, with better geometric stability.

\begin{figure}[H]
    \centering
    \begin{minipage}[t]{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{../../results/plots/harris/cpp_vs_maxloc_neighborhood_size.png}
        \vspace{2mm}
        \textbf{(a)} Cycles/pixel vs NMS neighborhood size
    \end{minipage}
    \hfill
    \begin{minipage}[t]{0.48\linewidth}
        \centering
        \includegraphics[width=\linewidth]{../../results/plots/harris/time_vs_maxloc_neighborhood_size.png}
        \vspace{2mm}
        \textbf{(b)} Mean time vs NMS neighborhood size
    \end{minipage}
    \caption{Impact of NMS neighborhood size on computational cost.}
    \label{fig:harris_maxloc_analysis}
\end{figure}

When \texttt{MAXLOC\_NEIGHBORHOOD\_SIZE} increases, the cost increases
moderately, because dilation/non-max suppression scans a larger neighborhood.
This parameter mainly acts on final point density:
a large neighborhood makes non-maximum suppression more aggressive
(fewer corners, better spacing, less redundancy), while a small neighborhood
lets more nearby local maxima pass
(more corners, but more spatial redundancy).

In summary, there is a classic tradeoff between sensitivity and robustness:
increasing detail sensitivity often produces more corners, but also
more noise and false corners; reinforcing robustness reduces false positives,
but may remove weak corners useful for some scenes.
For this image set, the baseline configuration
(\texttt{SUM\_WINDOW\_SIZE} = 5, \texttt{HARRIS\_K} = 0.04,
NMS neighborhood = 3) remains a reasonable compromise.

\subsection{Harris Computation at Multiple Scales}

In the current implementation of \texttt{Harris.py}, the detector is
single-scale: we use fixed Gaussian smoothing
(\texttt{sigma = 1.0}) as well as a fixed summation window to build
the structure matrix.
This approach works well for a given scale, but it loses
robustness when the apparent size of objects varies between images.

\textbf{Note.} Parameter \(\sigma\) represents the Gaussian smoothing
level: the larger \(\sigma\), the stronger the smoothing, and the more
fine image details are attenuated (or even erased).

To perform Harris computation at multiple scales, we work in
scale-space \((x,y,\sigma)\):
\begin{enumerate}
    \item Define a set of scales \(\sigma_1,\sigma_2,\dots,\sigma_n\)
    (or build a Gaussian pyramid).
    \item For each \(\sigma_i\), compute \(I_x\), \(I_y\), the matrix
    \(M_{\sigma_i}\), then the Harris response \(R_{\sigma_i}\).
    \item Normalize responses across scales to make them comparable.
    \item Apply 2D non-maximum suppression at each scale,
    then extend it to 3D:
    a point is kept if it is maximal in its spatial neighborhood and also
    relative to \(\sigma_{i-1}\), \(\sigma_i\), and \(\sigma_{i+1}\).
    \item Apply a threshold, then reproject the points into the original image
    while keeping their characteristic scale.
\end{enumerate}

The main tradeoffs are the following:
\begin{itemize}
    \item More scales: better robustness to size changes, but
    higher computational cost.
    \item Small scales: more details and potentially more corners,
    but also stronger sensitivity to noise.
    \item Large scales: more stable detection, but risk of losing
    fine or weak corners.
\end{itemize}

Finally, the link with minimum distance \(r\) between interest points is the following.
To guarantee that two detected points stay separated by at least \(r\) pixels,
we can use non-maximum suppression with radius \(r\), or
ANMS (\emph{Adaptive Non-Maximum Suppression}).
This reduces spatial redundancy and improves corner distribution
in the image.

Instead of using one fixed radius everywhere, ANMS assigns to each
candidate corner an adaptive radius \(r_i\), defined as the distance to the closest
stronger corner.
That is:
\begin{itemize}
    \item a very strong, isolated corner gets a large radius \(r_i\);
    \item a weak corner near a stronger corner gets a small radius.
\end{itemize}

Then, candidates are sorted by \(r_i\), and points with the
largest radii are kept.
This way, we keep corners that are both reliable (good Harris response) and well
distributed spatially, which is often preferable to a very dense
local selection in a small region of the image.
