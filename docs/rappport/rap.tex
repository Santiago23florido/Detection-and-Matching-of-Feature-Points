\documentclass[conference]{IEEEtran}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{float}
\usepackage{url}

% Reduce excessive vertical gaps around floats (tables/figures).
\setlength{\textfloatsep}{8pt plus 1pt minus 2pt}
\setlength{\floatsep}{8pt plus 1pt minus 2pt}
\setlength{\intextsep}{8pt plus 1pt minus 2pt}
\setlength{\abovecaptionskip}{4pt}
\setlength{\belowcaptionskip}{2pt}

\begin{document}

\title{Robust Image Matching with Local Features}

\author{
    \IEEEauthorblockN{1\textsuperscript{st} Santiago Florido Gomez}
    \IEEEauthorblockA{\textit{Ingénieur Degree Programme STIC} \\
    \textit{ENSTA Paris}\\
    Paris, France \\
    santiago.florido@ensta.fr}
    \and
    \IEEEauthorblockN{2\textsuperscript{nd} Javier Andres Tarazona Jimenez}
    \IEEEauthorblockA{\textit{Ingénieur Degree Programme STIC} \\
    \textit{ENSTA Paris}\\
    Paris, France \\
    javier-andres.tarazona@ensta.fr}
    \and
    \IEEEauthorblockN{3\textsuperscript{rd} José Daniel Chacón Gómez}
    \IEEEauthorblockA{\textit{Ingénieur Degree Programme STIC} \\
    \textit{ENSTA Paris}\\
    Paris, France \\
    jose-daniel.chacon@ensta.fr}
}

\maketitle

\begin{abstract}
This report presents a practical study of the local-feature pipeline for image matching, covering convolution fundamentals, interest-point detection, descriptor computation, and feature pairing. We first benchmark a direct Python convolution against OpenCV's optimized \texttt{filter2D}, observing a speedup of roughly $2\,100\times$, and analyze the sharpening kernel as a Laplacian-based unsharp mask together with Sobel gradient filters. We then examine the Harris corner detector, including its parametric sensitivity and extension to multi-scale operation. Two complete feature methods are compared in depth: ORB (Oriented FAST and Rotated BRIEF), a fast binary descriptor suited for real-time applications, and KAZE, which builds a nonlinear, edge-preserving scale space and produces a floating-point M-SURF descriptor. Matching strategies---cross-check, ratio test, and FLANN---are evaluated both qualitatively and quantitatively under controlled geometric transformations (rotation, scale, and synthetic viewpoint tilt). Results show that both methods achieve high precision under rotation and moderate scale changes, while KAZE consistently yields more correct correspondences under viewpoint variations, at the cost of significantly higher computation time.
\end{abstract}

\begin{IEEEkeywords}
local features, image matching, convolution, Harris corner detector, ORB, KAZE, feature descriptors, nonlinear scale space, unsharp masking, FLANN
\end{IEEEkeywords}

\input{sections/convolutions.tex}
\input{sections/detectors.tex}

\input{sections/descriptors_pairing.tex}


\begin{thebibliography}{00}

\bibitem{gonzalez_woods_dip}
R.~C. Gonzalez and R.~E. Woods, \emph{Digital Image Processing}, 4th~ed.\hskip 1em
Pearson, 2018.

\bibitem{opencv_filter2d}
OpenCV, ``cv::filter2D,'' \emph{OpenCV Documentation} (OpenCV 4.x), accessed Feb.~17, 2026. [Online]. Available: \url{https://docs.opencv.org/4.x/d4/d86/group__imgproc__filter.html}

\bibitem{opencv_feature_description}
A. Huam\'an, ``Feature Description,'' \emph{OpenCV Documentation} (OpenCV 4.14.0-pre), accessed Feb. 6, 2026. [Online]. Available: \url{https://docs.opencv.org/4.x/d5/dde/tutorial_feature_description.html}

\bibitem{opencv_feature_detection}
A. Huam\'an, ``Feature Detection,'' \emph{OpenCV Documentation} (OpenCV 4.14.0-pre), accessed Feb. 6, 2026. [Online]. Available: \url{https://docs.opencv.org/4.x/d7/d66/tutorial_feature_detection.html}

\bibitem{tuytelaars_mikolajczyk_features}
T. Tuytelaars and K. Mikolajczyk, ``Local Invariant Feature Detectors: A Survey,'' \emph{Foundations and Trends in Computer Graphics and Vision}, vol. 3, no. 3, pp. 177--280, 2007, accessed Feb. 6, 2026. [Online]. Available: \url{https://lvelho.impa.br/ip08/reading/features.pdf}

\bibitem{rublee_orb}
E. Rublee, V. Rabaud, K. Konolige, and G. Bradski, ``ORB: an efficient alternative to SIFT or SURF,'' in \emph{Proc. IEEE International Conference on Computer Vision (ICCV)}, Nov. 2011, doi: 10.1109/ICCV.2011.6126544, accessed Feb. 6, 2026. [Online]. Available: \url{https://sites.cc.gatech.edu/classes/AY2024/cs4475_summer/images/ORB_an_efficient_alternative_to_SIFT_or_SURF.pdf}

\bibitem{rosten_drummond_fast}
E. Rosten and T. Drummond, ``Machine learning for high-speed corner detection,'' in \emph{Computer Vision -- ECCV 2006} (Lecture Notes in Computer Science), vol. 3951, pp. 430--443, 2006, accessed Feb. 6, 2026. [Online]. Available: \url{https://www.edwardrosten.com/work/rosten_2006_machine.pdf}

\bibitem{opencv_orb_class}
OpenCV, ``cv::ORB Class Reference,'' \emph{OpenCV Documentation} (OpenCV 3.4), accessed Feb. 6, 2026. [Online]. Available: \url{https://docs.opencv.org/3.4/db/d95/classcv_1_1ORB.html}

\bibitem{calonder_brief}
M. Calonder, V. Lepetit, C. Strecha, and P. Fua, ``BRIEF: Binary Robust Independent Elementary Features,'' in \emph{Proc. European Conference on Computer Vision (ECCV)}, 2010, accessed Feb. 6, 2026. [Online]. Available: \url{https://www.cs.ubc.ca/~lowe/525/papers/calonder_eccv10.pdf}

\bibitem{alcantarilla_kaze}
P. F. Alcantarilla, A. Bartoli, and A. J. Davison, ``KAZE Features,'' in \emph{Proc. European Conference on Computer Vision (ECCV)}, 2012, accessed Feb. 6, 2026. [Online]. Available: \url{https://www.doc.ic.ac.uk/~ajd/Publications/alcantarilla_etal_eccv2012.pdf}

\bibitem{perona_malik_1990}
P. Perona and J. Malik, ``Scale-space and edge detection using anisotropic diffusion,'' \emph{IEEE Transactions on Pattern Analysis and Machine Intelligence}, vol. 12, no. 7, pp. 629--639, 1990, accessed Feb. 6, 2026. [Online]. Available: https://www.sci.utah.edu/~gerig/CS7960-S2010/materials/Perona-Malik/PeronaMalik-PAMI-1990.pdf

\bibitem{bay_surf_2008}
H. Bay, A. Ess, T. Tuytelaars, and L. Van Gool, ``SURF: Speeded Up Robust Features,'' \emph{Computer Vision and Image Understanding}, vol. 110, no. 3, pp. 346--359, 2008, accessed Feb. 6, 2026. [Online]. Available: https://www.cs.jhu.edu/~misha/ReadingSeminar/Papers/Bay08.pdf

\bibitem{manzanera_cours1}
A.~Manzanera, ``Cours n\textsuperscript{o}1~: Introduction --- Mod\`eles et outils fondamentaux,'' \emph{Cours CSC\_4MI04 --- Reconnaissance d'Images}, ENSTA Paris, 2025--2026.

\bibitem{manzanera_cours2}
A.~Manzanera, ``Cours n\textsuperscript{o}2~: Caract\'eristiques multi-\'echelles,'' \emph{Cours CSC\_4MI04 --- Reconnaissance d'Images}, ENSTA Paris, 2025--2026.
\bibitem{rublee_orb_2011}
E. Rublee, V. Rabaud, K. Konolige, and G. R. Bradski, ``ORB: An efficient alternative to SIFT or SURF,'' in \emph{Proc. IEEE International Conference on Computer Vision (ICCV)}, 2011, pp. 2564--2571, doi: 10.1109/ICCV.2011.6126544, accessed Feb. 18, 2026.

\bibitem{alcantarilla_kaze_2012}
P. F. Alcantarilla, A. Bartoli, and A. J. Davison, ``KAZE Features,'' in \emph{Computer Vision--ECCV 2012}, Lecture Notes in Computer Science, vol. 7577. Springer, 2012, pp. 214--227, doi: 10.1007/978-3-642-33783-3\_16, accessed Feb. 18, 2026.

\bibitem{opencv_orb_class_reference}
OpenCV, ``cv::ORB Class Reference,'' \emph{OpenCV Documentation}, accessed Feb. 18, 2026. [Online]. Available: \url{https://docs.opencv.org/3.4/db/d95/classcv_1_1ORB.html}

\end{thebibliography}

\end{document}
